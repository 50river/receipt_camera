<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <!-- レスポンシブ対応のためのviewport設定 -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>領収書OCRアプリ</title>
  <style>
    /* 全体レイアウト */
    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background: #f0f0f0;
    }
    #app {
      width: 100%;
      max-width: 600px;
      margin: 0 auto;
      background: #fff;
      min-height: 100vh;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    /* ヘッダー */
    #header {
      background: #007aff;
      color: #fff;
      padding: 10px;
      text-align: center;
    }
    /* 画面（スクリーン）のスタイル */
    .screen {
      display: none;
      padding: 10px;
    }
    .screen.active {
      display: block;
    }
    h1, h2, h3, p {
      margin: 10px 0;
    }
    hr {
      margin: 20px 0;
    }
    /* キャンバス等 */
    #pcCanvasContainer, #fsCanvasContainer {
      position: relative;
      margin: 0 auto;
    }
    /* キャンバスは内部サイズを設定し、表示はCSSで横幅100%に */
    #pcCanvas, #fsCanvas {
      border: 1px solid #ccc;
      cursor: crosshair;
      display: block;
      width: 100%;
      height: auto;
      touch-action: none;
    }
    /* ボタンとドロップダウン */
    button, select {
      margin: 10px 5px;
      font-size: 1.5em;
      padding: 0.15em 0.25em;
    }
    /* 補正結果画像 */
    #correctedImage {
      border: 1px solid #ccc;
      max-width: 50%;
      display: block;
      margin: 10px auto;
    }
    /* 入力フィールド */
    .field-group {
      margin-top: 15px;
    }
    label {
      display: inline-block;
      width: 80px;
    }
    input[type="text"] {
      width: calc(100% - 90px);
      padding: 3px;
    }
    /* 編集用の枠（ポイント）の初期サイズ：ここではポイントは15pxの半径、ライン太さは4px */
    .point {
      position: absolute;
      width: 12px;  /* この値は後でcanvas上で直接描画するので、drawPcCanvasWithPoints()内で変更します */
      height: 12px;
      background: blue;
      border-radius: 50%;
      transform: translate(-50%, -50%);
      pointer-events: none;
    }
    /* メディアクエリ例（画面幅600px未満の場合） */
    @media (max-width: 600px) {
      #header {
        padding: 8px;
        font-size: 1.2em;
      }
      button, select {
        font-size: 1.2em;
        padding: 0.1em 0.2em;
      }
      input[type="text"] {
        font-size: 1em;
      }
    }
  </style>
</head>
<body>
  <div id="app">
    <!-- ヘッダー -->
    <div id="header">
      <h1>領収書OCRアプリ</h1>
    </div>
    
    <!-- スクリーン1：画像切り出し＆補正 -->
    <div id="screen1" class="screen active">
      <h2>画像切り出し＆補正</h2>
      <p>画像ファイルを選択し、クロッピング用の編集枠を調整してください。</p>
      <input type="file" id="imageInput" accept="image/*">
      <div id="pcCanvasContainer">
        <canvas id="pcCanvas"></canvas>
      </div>
      <button id="autoCropButton">自動切り出し＆補正を実行</button>
      <button id="confirmPointsButton" style="display:none;">ポイント確定</button>
      <h3>補正結果</h3>
      <img id="correctedImage" alt="Corrected Image">
      <!-- 回転・反転ボタン（必要なら） -->
      <div id="transformControls" style="margin-top:10px; display:none;">
        <button id="rotate90Button">Rotate 90°</button>
        <button id="rotateNeg90Button">Rotate -90°</button>
        <button id="flipButton">Flip Horizontally</button>
      </div>
      <br>
      <button id="nextToScreen2">次へ</button>
    </div>
    
    <!-- スクリーン2：フィールド選択＆OCR -->
    <div id="screen2" class="screen">
      <h2>フィールド選択＆OCR</h2>
      <p>補正済み画像上で、各フィールドの領域を指定してください。</p>
      <label for="fieldSelector">対象項目:</label>
      <select id="fieldSelector">
        <option value="">--フィールドを選択--</option>
        <option value="date">日付</option>
        <option value="amount">金額</option>
        <option value="payee">支払先</option>
        <option value="description">摘要</option>
      </select>
      <div id="fsCanvasContainer">
        <canvas id="fsCanvas"></canvas>
      </div>
      <button id="fsResetButton">フィールドリセット</button>
      <button id="fsOcrButton">選択領域でOCR実行</button>
      <h3>OCR結果</h3>
      <pre id="ocrOutput"></pre>
      <div class="field-group">
        <label for="dateField">日付:</label>
        <input type="text" id="dateField" placeholder="OCR結果">
      </div>
      <div class="field-group">
        <label for="amountField">金額:</label>
        <input type="text" id="amountField" placeholder="OCR結果">
      </div>
      <div class="field-group">
        <label for="payeeField">支払先:</label>
        <input type="text" id="payeeField" placeholder="OCR結果">
      </div>
      <div class="field-group">
        <label for="descriptionField">摘要:</label>
        <input type="text" id="descriptionField" placeholder="OCR結果">
      </div>
      <button id="backToScreen1">戻る</button>
    </div>
  </div>
  
  <!-- ライブラリ読み込み -->
  <!-- Tesseract.js 最新版（安定版ではなく最新版） -->
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@6.0.0/dist/tesseract.min.js"></script>
  <!-- OpenCV.js -->
  <script async src="https://docs.opencv.org/3.4.0/opencv.js" onload="onOpenCvReady();"></script>
  
  <script>
    /***********************************************************************
     * 変数一覧と用途:
     * 
     * pcScale           : PCキャンバス上で表示される画像のスケール（内部サイズ/表示サイズ）
     * fsScale           : FSキャンバス上で表示される画像のスケール
     * detectedPoints    : PCキャンバス上で検出（またはデフォルト）された4点（クロッピング用）
     * draggingPointIndex: ドラッグ中のポイントのインデックス（ドラッグしていなければ -1）
     * AREA_THRESHOLD    : 輪郭検出時に使用する面積の閾値
     * 
     * pcCanvas, pcCtx   : PCキャンバス要素とその2Dコンテキスト（自動切り出し＆補正用）
     * pcImage           : アップロードされたオリジナル画像
     * imageInput        : 画像ファイル選択用の input 要素
     * autoCropButton    : 自動切り出し＆補正を実行するボタン
     * confirmPointsButton: ユーザーが編集したクロッピング用の4点を確定するボタン
     * correctedImage    : 補正後の画像を表示する img 要素
     * loadFsButton      : 補正後画像をFSモードに読み込むボタン
     * transformControls : 画像の回転・反転操作用ボタンを含むコンテナ
     * 
     * fsCanvas, fsCtx   : FSキャンバス要素とその2Dコンテキスト（フィールド選択用）
     * fsImage           : 補正後画像をFSモードで利用するためのImageオブジェクト
     * fsFieldRegions    : フィールド選択でユーザーが選択した領域（各フィールド名をキーとする）
     * fieldSelector     : OCR対象フィールド（日付、金額、支払先、摘要）を選択するドロップダウン
     * fsResetButton     : FSモードでフィールド選択をリセットするボタン
     * fsOcrButton       : 選択した領域でOCRを実行するボタン
     * ocrOutput         : OCR結果を表示するpre要素
     * dateField, amountField, payeeField, descriptionField:
     *                   各フィールドのOCR結果を表示するテキスト入力欄
     ***********************************************************************/
    
    // 画面遷移用関数
    function showScreen(screenId) {
      const screens = document.querySelectorAll('.screen');
      screens.forEach(screen => {
        if (screen.id === screenId) {
          screen.classList.add('active');
        } else {
          screen.classList.remove('active');
        }
      });
      // 画面遷移後にキャンバスの再描画
      if(screenId === 'screen1') {
        drawPcCanvasWithPoints();
      }
      if(screenId === 'screen2') {
        drawFsCanvas();
      }
    }
    
    // 画面遷移ボタン
    document.getElementById('nextToScreen2').addEventListener('click', function() {
      if (!correctedImage.src) {
        alert("補正結果画像がありません。");
        return;
      }
      showScreen('screen2');
    });
    
    document.getElementById('backToScreen1').addEventListener('click', function() {
      showScreen('screen1');
    });
    
    // -------------------- PC（切り出し＆補正）モード --------------------
    let pcScale = 1;      // 元画像からキャンバスへの表示スケール
    let detectedPoints = [];  // 自動検出またはデフォルトの4点
    let draggingPointIndex = -1; // ドラッグ中のポイントインデックス（なければ -1）
    const AREA_THRESHOLD = 10000;  // 輪郭検出に使用する面積閾値
    
    const pcCanvas = document.getElementById('pcCanvas');
    const pcCtx = pcCanvas.getContext('2d');
    let pcImage = new Image();
    
    const imageInput = document.getElementById('imageInput');
    const autoCropButton = document.getElementById('autoCropButton');
    const confirmPointsButton = document.getElementById('confirmPointsButton');
    const correctedImage = document.getElementById('correctedImage');
    const loadFsButton = document.getElementById('loadFsButton');
    const transformControls = document.getElementById('transformControls');
    
    // 画像ファイル選択時：画像を読み込む
    imageInput.addEventListener('change', function(e) {
      if (e.target.files.length > 0) {
        const file = e.target.files[0];
        const reader = new FileReader();
        reader.onload = function(event) {
          pcImage.src = event.target.result;
        };
        reader.readAsDataURL(file);
      }
    });
    
    // pcImage読み込み後：キャンバスに画像を描画
    pcImage.onload = function() {
      let maxDisplayWidth = window.innerWidth - 40;
      pcScale = (pcImage.width > maxDisplayWidth) ? (maxDisplayWidth / pcImage.width) : 1;
      // キャンバス内部サイズは元画像サイズにスケールを掛けたもの
      pcCanvas.width = pcImage.width * pcScale;
      pcCanvas.height = pcImage.height * pcScale;
      pcCtx.clearRect(0, 0, pcCanvas.width, pcCanvas.height);
      pcCtx.drawImage(pcImage, 0, 0, pcCanvas.width, pcCanvas.height);
      detectedPoints = [];
      confirmPointsButton.style.display = "none";
      transformControls.style.display = "none";
    };
    
    // 自動輪郭検出（autoCrop関数）
    function autoCrop() {
      if (!pcImage.src) {
        alert("画像が読み込まれていません。");
        return;
      }
      let srcMat = cv.imread(pcCanvas);
      let gray = new cv.Mat();
      cv.cvtColor(srcMat, gray, cv.COLOR_RGBA2GRAY, 0);
      let blurred = new cv.Mat();
      cv.GaussianBlur(gray, blurred, new cv.Size(7, 7), 0);
      let edges = new cv.Mat();
      cv.Canny(blurred, edges, 50, 150);
      let kernel = cv.Mat.ones(3, 3, cv.CV_8U);
      let dilated = new cv.Mat();
      cv.dilate(edges, dilated, kernel);
      
      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(dilated, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);
      
      let maxArea = 0;
      let bestContour = null;
      for (let i = 0; i < contours.size(); i++) {
        let cnt = contours.get(i);
        let peri = cv.arcLength(cnt, true);
        let approx = new cv.Mat();
        cv.approxPolyDP(cnt, approx, 0.02 * peri, true);
        if (approx.rows === 4) {
          let area = cv.contourArea(approx);
          console.log("Contour " + i + " area:", area);
          if (area > AREA_THRESHOLD && area > maxArea) {
            maxArea = area;
            if (bestContour !== null) bestContour.delete();
            bestContour = approx;
          } else {
            approx.delete();
          }
        } else {
          approx.delete();
        }
        cnt.delete();
      }
      hierarchy.delete();
      edges.delete();
      dilated.delete();
      kernel.delete();
      blurred.delete();
      gray.delete();
      
      // 輪郭検出が失敗した場合：キャンバスの左右上下10%の余白を持つ枠を設定
      if (bestContour === null) {
        const marginX = pcCanvas.width * 0.1;
        const marginY = pcCanvas.height * 0.1;
        detectedPoints = [
          { x: marginX, y: marginY },
          { x: pcCanvas.width - marginX, y: marginY },
          { x: pcCanvas.width - marginX, y: pcCanvas.height - marginY },
          { x: marginX, y: pcCanvas.height - marginY }
        ];
        console.log("輪郭検出できなかったため、余白付きのデフォルト枠を設定");
        drawPcCanvasWithPoints();
        confirmPointsButton.style.display = "inline-block";
        srcMat.delete();
        return;
      }
      
      // 検出された輪郭の4点を取得
      detectedPoints = [];
      for (let i = 0; i < 4; i++) {
        detectedPoints.push({
          x: bestContour.intAt(i, 0),
          y: bestContour.intAt(i, 1)
        });
      }
      bestContour.delete();
      
      // 4点を [tl, tr, br, bl] の順に並び替え
      detectedPoints = orderPoints(detectedPoints);
      console.log("検出された4点（整列後）:", detectedPoints);
      drawPcCanvasWithPoints();
      confirmPointsButton.style.display = "inline-block";
      
      srcMat.delete();
    }
    
    // 4点を正しい順序に並び替える関数（[tl, tr, br, bl]の順）
    function orderPoints(pts) {
      let sumArr = pts.map(p => p.x + p.y);
      let diffArr = pts.map(p => p.x - p.y);
      let tl = pts[sumArr.indexOf(Math.min(...sumArr))];
      let br = pts[sumArr.indexOf(Math.max(...sumArr))];
      let tr = pts[diffArr.indexOf(Math.min(...diffArr))];
      let bl = pts[diffArr.indexOf(Math.max(...diffArr))];
      return [tl, tr, br, bl];
    }
    
    // PCキャンバスに画像と編集用のポイント・ラインを描画する関数
    // ポイントの半径を15px、連結線の太さを4pxに設定
    function drawPcCanvasWithPoints() {
      pcCtx.clearRect(0, 0, pcCanvas.width, pcCanvas.height);
      pcCtx.drawImage(pcImage, 0, 0, pcCanvas.width, pcCanvas.height);
      detectedPoints.forEach(pt => {
        pcCtx.beginPath();
        pcCtx.arc(pt.x, pt.y, 15, 0, 2 * Math.PI);
        pcCtx.fillStyle = "blue";
        pcCtx.fill();
      });
      if (detectedPoints.length === 4) {
        pcCtx.beginPath();
        pcCtx.moveTo(detectedPoints[0].x, detectedPoints[0].y);
        for (let i = 1; i < 4; i++) {
          pcCtx.lineTo(detectedPoints[i].x, detectedPoints[i].y);
        }
        pcCtx.closePath();
        pcCtx.strokeStyle = "blue";
        pcCtx.lineWidth = 4;
        pcCtx.stroke();
      }
    }
    
    autoCropButton.addEventListener('click', autoCrop);
    
    // PCキャンバスの pointer イベント：表示サイズと内部サイズの比率を使って正確な内部座標に変換
    pcCanvas.addEventListener('pointerdown', function(e) {
      if (detectedPoints.length !== 4) return;
      e.preventDefault();
      const rect = pcCanvas.getBoundingClientRect();
      const scaleX = pcCanvas.width / rect.width;
      const scaleY = pcCanvas.height / rect.height;
      const x = (e.clientX - rect.left) * scaleX;
      const y = (e.clientY - rect.top) * scaleY;
      draggingPointIndex = -1;
      // ポイント検出の許容誤差は15pxに設定
      for (let i = 0; i < 4; i++) {
        let pt = detectedPoints[i];
        if (Math.hypot(pt.x - x, pt.y - y) < 15) {
          draggingPointIndex = i;
          break;
        }
      }
    });
    
    pcCanvas.addEventListener('pointermove', function(e) {
      if (draggingPointIndex === -1) return;
      e.preventDefault();
      const rect = pcCanvas.getBoundingClientRect();
      const scaleX = pcCanvas.width / rect.width;
      const scaleY = pcCanvas.height / rect.height;
      const x = (e.clientX - rect.left) * scaleX;
      const y = (e.clientY - rect.top) * scaleY;
      detectedPoints[draggingPointIndex] = { x, y };
      drawPcCanvasWithPoints();
    });
    
    pcCanvas.addEventListener('pointerup', function(e) {
      e.preventDefault();
      draggingPointIndex = -1;
    });
    
    // ポイント確定ボタン：ユーザーが調整した4点をもとにパースペクティブ変換を実施
    confirmPointsButton.addEventListener('click', function() {
      if (detectedPoints.length !== 4) {
        alert("4点が設定されていません。");
        return;
      }
      let ptsOriginal = detectedPoints.map(pt => ({ x: pt.x / pcScale, y: pt.y / pcScale }));
      ptsOriginal = orderPoints(ptsOriginal);
      let [tl, tr, br, bl] = ptsOriginal;
      
      let widthA = Math.hypot(br.x - bl.x, br.y - bl.y);
      let widthB = Math.hypot(tr.x - tl.x, tr.y - tl.y);
      let maxWidth = Math.max(widthA, widthB);
      
      let heightA = Math.hypot(tr.x - br.x, tr.y - br.y);
      let heightB = Math.hypot(tl.x - bl.x, tl.y - bl.y);
      let maxHeight = Math.max(heightA, heightB);
      
      let offCanvas = document.createElement('canvas');
      offCanvas.width = pcImage.width;
      offCanvas.height = pcImage.height;
      let offCtx = offCanvas.getContext('2d');
      offCtx.drawImage(pcImage, 0, 0);
      let srcMat = cv.imread(offCanvas);
      
      let srcPts = cv.matFromArray(4, 1, cv.CV_32FC2, [
        tl.x, tl.y,
        tr.x, tr.y,
        br.x, br.y,
        bl.x, bl.y
      ]);
      let dstPts = cv.matFromArray(4, 1, cv.CV_32FC2, [
        0, 0,
        maxWidth - 1, 0,
        maxWidth - 1, maxHeight - 1,
        0, maxHeight - 1
      ]);
      
      let M = cv.getPerspectiveTransform(srcPts, dstPts);
      let dsize = new cv.Size(maxWidth, maxHeight);
      let dstMat = new cv.Mat();
      cv.warpPerspective(srcMat, dstMat, M, dsize, cv.INTER_LINEAR, cv.BORDER_CONSTANT, new cv.Scalar());
      
      let tempCanvas = document.createElement('canvas');
      tempCanvas.width = maxWidth;
      tempCanvas.height = maxHeight;
      cv.imshow(tempCanvas, dstMat);
      let croppedDataURL = tempCanvas.toDataURL();
      
      // 補正後の画像を自動で90°回転＋水平反転して最終画像とする
      rotateImage(croppedDataURL, 90)
        .then(rotatedDataURL => flipImage(rotatedDataURL))
        .then(finalDataURL => {
          correctedImage.src = finalDataURL;
          fsImage.src = finalDataURL;
          transformControls.style.display = "block";
        });
      
      srcMat.delete(); dstMat.delete(); srcPts.delete(); dstPts.delete(); M.delete();
      
      detectedPoints = [];
      confirmPointsButton.style.display = "none";
    });
    
    // -------------------- FS（フィールド選択＆OCR）モード --------------------
    let fsImage = new Image();
    const fsCanvas = document.getElementById('fsCanvas');
    const fsCtx = fsCanvas.getContext('2d');
    let fsFieldRegions = {};  // 各フィールド名をキーとした、領域情報オブジェクト
    
    const fieldSelector = document.getElementById('fieldSelector');
    const fsResetButton = document.getElementById('fsResetButton');
    const fsOcrButton = document.getElementById('fsOcrButton');
    const ocrOutput = document.getElementById('ocrOutput');
    const dateField = document.getElementById('dateField');
    const amountField = document.getElementById('amountField');
    const payeeField = document.getElementById('payeeField');
    const descriptionField = document.getElementById('descriptionField');
    
    fsImage.onload = function() {
      let maxDisplayWidth = window.innerWidth - 40;
      fsScale = (fsImage.width > maxDisplayWidth) ? (maxDisplayWidth / fsImage.width) : 1;
      fsCanvas.width = fsImage.width * fsScale;
      fsCanvas.height = fsImage.height * fsScale;
      fsFieldRegions = {};
      drawFsCanvas();
    };
    
    function drawFsCanvas() {
      fsCtx.clearRect(0, 0, fsCanvas.width, fsCanvas.height);
      fsCtx.drawImage(fsImage, 0, 0, fsCanvas.width, fsCanvas.height);
      // フィールド選択枠の描画（ライン太さ4px）
      for (const field in fsFieldRegions) {
        if (field === "amount" && Array.isArray(fsFieldRegions[field])) {
          fsFieldRegions[field].forEach(region => {
            fsCtx.strokeStyle = "red";
            fsCtx.lineWidth = 4;
            fsCtx.strokeRect(region.x, region.y, region.width, region.height);
            fsCtx.fillStyle = "rgba(255,255,255,0.7)";
            fsCtx.fillRect(region.x, region.y - 20, 60, 20);
            fsCtx.fillStyle = "red";
            fsCtx.font = "14px Arial";
            fsCtx.fillText(field, region.x + 2, region.y - 5);
          });
        } else {
          const r = fsFieldRegions[field];
          fsCtx.strokeStyle = "red";
          fsCtx.lineWidth = 4;
          fsCtx.strokeRect(r.x, r.y, r.width, r.height);
          fsCtx.fillStyle = "rgba(255,255,255,0.7)";
          fsCtx.fillRect(r.x, r.y - 20, 50, 20);
          fsCtx.fillStyle = "red";
          fsCtx.font = "14px Arial";
          fsCtx.fillText(field, r.x + 2, r.y - 5);
        }
      }
    }
    
    // FSキャンバスの描画：ユーザーがドラッグして選択した領域の座標を正しく取得
    let fsIsDrawing = false;
    let fsStartX, fsStartY, fsCurrentX, fsCurrentY;
    
    fsCanvas.addEventListener('pointerdown', function(e) {
      if (!fieldSelector.value) {
        alert("まずは対象項目を選択してください。");
        return;
      }
      e.preventDefault();
      const rect = fsCanvas.getBoundingClientRect();
      const scaleX = fsCanvas.width / rect.width;
      const scaleY = fsCanvas.height / rect.height;
      fsStartX = (e.clientX - rect.left) * scaleX;
      fsStartY = (e.clientY - rect.top) * scaleY;
      fsIsDrawing = true;
    });
    
    fsCanvas.addEventListener('pointermove', function(e) {
      if (!fsIsDrawing) return;
      e.preventDefault();
      const rect = fsCanvas.getBoundingClientRect();
      const scaleX = fsCanvas.width / rect.width;
      const scaleY = fsCanvas.height / rect.height;
      fsCurrentX = (e.clientX - rect.left) * scaleX;
      fsCurrentY = (e.clientY - rect.top) * scaleY;
      drawFsCanvas();
      fsCtx.strokeStyle = "blue";
      fsCtx.lineWidth = 4;
      fsCtx.strokeRect(fsStartX, fsStartY, fsCurrentX - fsStartX, fsCurrentY - fsStartY);
    });
    
    fsCanvas.addEventListener('pointerup', function(e) {
      if (!fsIsDrawing) return;
      e.preventDefault();
      fsIsDrawing = false;
      const rect = fsCanvas.getBoundingClientRect();
      const scaleX = fsCanvas.width / rect.width;
      const scaleY = fsCanvas.height / rect.height;
      fsCurrentX = (e.clientX - rect.left) * scaleX;
      fsCurrentY = (e.clientY - rect.top) * scaleY;
      const x = Math.min(fsStartX, fsCurrentX);
      const y = Math.min(fsStartY, fsCurrentY);
      const width = Math.abs(fsCurrentX - fsStartX);
      const height = Math.abs(fsCurrentY - fsStartY);
      if (width === 0 || height === 0) return;
      const field = fieldSelector.value;
      if (field === "amount") {
        if (!fsFieldRegions[field]) {
          fsFieldRegions[field] = [];
        }
        fsFieldRegions[field].push({ x, y, width, height });
      } else {
        fsFieldRegions[field] = { x, y, width, height };
      }
      drawFsCanvas();
    });
    
    fsResetButton.addEventListener('click', function() {
      fsFieldRegions = {};
      drawFsCanvas();
    });
    
    fsOcrButton.addEventListener('click', function() {
      ocrOutput.textContent = "各領域のOCR処理中…\n";
      const tasks = [];
      for (const field in fsFieldRegions) {
        if (field === "amount" && Array.isArray(fsFieldRegions[field])) {
          let amountPromises = fsFieldRegions[field].map(region => performOCROnField("amount", region));
          tasks.push(
            Promise.all(amountPromises).then(results => {
              let total = results.reduce((sum, text) => {
                let num = parseInt(processAmountField(text), 10);
                return sum + (isNaN(num) ? 0 : num);
              }, 0);
              amountField.value = total;
              ocrOutput.textContent += `amount: ${total}\n`;
            })
          );
        } else {
          tasks.push(
            performOCROnField(field, fsFieldRegions[field])
              .then(resultText => {
                if (field === "date") {
                  resultText = processDateField(resultText);
                  dateField.value = resultText;
                } else if (field === "payee") {
                  payeeField.value = resultText;
                } else if (field === "description") {
                  descriptionField.value = resultText;
                }
                ocrOutput.textContent += `${field}: ${resultText}\n`;
              })
          );
        }
      }
      Promise.all(tasks).then(() => {
        ocrOutput.textContent += "全領域のOCR処理完了。";
      });
    });
    
    // FSモード：指定領域でOCRを実行する関数
    function performOCROnField(field, region) {
      return new Promise((resolve, reject) => {
        // FSキャンバス上の領域座標を元画像の座標に変換
        let originalX = region.x / fsScale;
        let originalY = region.y / fsScale;
        let originalWidth = region.width / fsScale;
        let originalHeight = region.height / fsScale;
        
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = originalWidth;
        tempCanvas.height = originalHeight;
        const tempCtx = tempCanvas.getContext('2d');
        tempCtx.drawImage(fsImage, originalX, originalY, originalWidth, originalHeight, 0, 0, originalWidth, originalHeight);
        const croppedDataURL = tempCanvas.toDataURL();
        // 2値化処理でOCR精度向上
        binarizeImage(croppedDataURL).then(binarizedDataURL => {
          Tesseract.recognize(
            binarizedDataURL,
            'jpn',
            {
              langPath: 'https://tessdata.projectnaptha.com/4.0.0_best/',
              logger: m => console.log(field, m),
              tessedit_char_whitelist: '0123456789年月日-/： ',
              tessedit_pageseg_mode: 6
            }
          ).then(({ data: { text } }) => {
            const processedText = replaceCircledNumbers(text).trim();
            resolve(processedText);
          }).catch(err => {
            console.error(field, err);
            resolve("エラー");
          });
        }).catch(err => {
          console.error("Binarization error", err);
          resolve("エラー");
        });
      });
    }
    
    // 画像を2値化してOCR精度向上のための画像に変換
    function binarizeImage(dataURL) {
      return new Promise((resolve, reject) => {
        let img = new Image();
        img.onload = function() {
          let canvas = document.createElement('canvas');
          canvas.width = img.width;
          canvas.height = img.height;
          let ctx = canvas.getContext('2d');
          ctx.drawImage(img, 0, 0);
          let src = cv.imread(canvas);
          let gray = new cv.Mat();
          cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
          let binary = new cv.Mat();
          cv.threshold(gray, binary, 128, 255, cv.THRESH_BINARY);
          cv.imshow(canvas, binary);
          let resultDataURL = canvas.toDataURL();
          src.delete(); gray.delete(); binary.delete();
          resolve(resultDataURL);
        };
        img.onerror = function(err) {
          reject(err);
        };
        img.src = dataURL;
      });
    }
    
    // 丸囲み数字を通常の数字に置換する関数
    function replaceCircledNumbers(text) {
      const mapping = {
        '⓪': '0', '①': '1', '②': '2', '③': '3', '④': '4',
        '⑤': '5', '⑥': '6', '⑦': '7', '⑧': '8', '⑨': '9',
        '⑩': '10', '⑪': '11', '⑫': '12'
      };
      return text.replace(/[⓪①②③④⑤⑥⑦⑧⑨⑩⑪⑫]/g, function(match) {
        return mapping[match] || match;
      });
    }
    
    // 日付フィールド用の後処理（和暦を西暦に変換など）
    function processDateField(text) {
      if (text.includes("令和") || text.includes("平成") || text.includes("昭和")) {
        return convertJapaneseEra(text);
      }
      return text;
    }
    
    // 金額フィールド用の後処理（数字以外を除去）
    function processAmountField(text) {
      return text.replace(/\D/g, "");
    }
    
    // 和暦を西暦に変換する関数
    function convertJapaneseEra(dateStr) {
      let match = dateStr.match(/(令和|平成|昭和)(元|\d+)[年](\d{1,2})[月](\d{1,2})[日]/);
      if (match) {
        let era = match[1];
        let yearPart = match[2];
        let month = match[3];
        let day = match[4];
        let offset = 0;
        if (era === "令和") offset = 2018;
        else if (era === "平成") offset = 1988;
        else if (era === "昭和") offset = 1925;
        let year;
        if (yearPart === "元") {
          year = offset + 1;
        } else {
          year = parseInt(yearPart, 10) + offset;
        }
        return year + "年" + month + "月" + day + "日";
      }
      return dateStr;
    }
    
    // 回転・反転操作用
    const rotate90Button = document.getElementById('rotate90Button');
    const rotateNeg90Button = document.getElementById('rotateNeg90Button');
    const flipButton = document.getElementById('flipButton');
    
    rotate90Button.addEventListener('click', function() {
      rotateImage(correctedImage.src, 90).then(newDataURL => {
        correctedImage.src = newDataURL;
        fsImage.src = newDataURL;
      });
    });
    
    rotateNeg90Button.addEventListener('click', function() {
      rotateImage(correctedImage.src, -90).then(newDataURL => {
        correctedImage.src = newDataURL;
        fsImage.src = newDataURL;
      });
    });
    
    flipButton.addEventListener('click', function() {
      flipImage(correctedImage.src).then(newDataURL => {
        correctedImage.src = newDataURL;
        fsImage.src = newDataURL;
      });
    });
    
    // 画像を指定角度回転する関数（dataURLを受け取り、回転後のdataURLを返す）
    function rotateImage(dataURL, angle) {
      return new Promise((resolve, reject) => {
        let img = new Image();
        img.onload = function() {
          let canvas = document.createElement('canvas');
          let ctx = canvas.getContext('2d');
          if (angle % 180 !== 0) {
            canvas.width = img.height;
            canvas.height = img.width;
          } else {
            canvas.width = img.width;
            canvas.height = img.height;
          }
          ctx.save();
          ctx.translate(canvas.width / 2, canvas.height / 2);
          ctx.rotate(angle * Math.PI / 180);
          ctx.drawImage(img, -img.width / 2, -img.height / 2);
          ctx.restore();
          resolve(canvas.toDataURL());
        };
        img.onerror = reject;
        img.src = dataURL;
      });
    }
    
    // 画像を水平反転する関数
    function flipImage(dataURL) {
      return new Promise((resolve, reject) => {
        let img = new Image();
        img.onload = function() {
          let canvas = document.createElement('canvas');
          canvas.width = img.width;
          canvas.height = img.height;
          let ctx = canvas.getContext('2d');
          ctx.save();
          ctx.translate(img.width, 0);
          ctx.scale(-1, 1);
          ctx.drawImage(img, 0, 0);
          ctx.restore();
          resolve(canvas.toDataURL());
        };
        img.onerror = reject;
        img.src = dataURL;
      });
    }
    
    // loadFsButton：補正済み画像をFSモードへ内部保存・再読み込み
    loadFsButton.addEventListener('click', function() {
      if (!correctedImage.src) {
        alert("まず、補正を実行してください。");
        return;
      }
      let storedDataURL = correctedImage.src + "?t=" + new Date().getTime();
      console.log("loadFsButton: storedDataURL =", storedDataURL);
      fsImage.onload = function() {
        fsScale = (fsImage.width > (window.innerWidth - 40)) ? ((window.innerWidth - 40) / fsImage.width) : 1;
        fsCanvas.width = fsImage.width * fsScale;
        fsCanvas.height = fsImage.height * fsScale;
        console.log("FS Canvas size:", fsCanvas.width, fsCanvas.height);
        drawFsCanvas();
      };
      fsImage.src = storedDataURL;
    });
    // fsImageの再初期化は行わない
  </script>
</body>
</html>
