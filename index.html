<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>領収書OCRアプリ</title>
  <style>
    /* 全体レイアウト */
    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background: #f0f0f0;
    }
    #app {
      width: 100%;
      max-width: 600px;
      margin: 0 auto;
      background: #fff;
      min-height: 100vh;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
    /* ヘッダー */
    #header {
      background: #007aff;
      color: #fff;
      padding: 10px;
      text-align: center;
    }
    /* 各スクリーンのスタイル */
    .screen {
      display: none;
      padding: 10px;
    }
    .screen.active {
      display: block;
    }
    h1, h2, h3, p {
      margin: 10px 0;
    }
    hr {
      margin: 20px 0;
    }
    /* キャンバス等 */
    #pcCanvasContainer, #fsCanvasContainer {
      position: relative;
      margin: 0 auto;
    }
    #pcCanvas, #fsCanvas {
      border: 1px solid #ccc;
      cursor: crosshair;
      display: block;
      width: 100%;
      height: auto;
      touch-action: none;
    }
    /* ボタンとドロップダウン */
    button, select {
      margin: 10px 5px;
      font-size: 1.5em;
      padding: 0.15em 0.25em;
    }
    /* 補正結果画像 */
    #correctedImage {
      border: 1px solid #ccc;
      max-width: 50%;
      display: block;
      margin: 10px auto;
    }
    /* 入力フィールド */
    .field-group {
      margin-top: 15px;
    }
    label {
      display: inline-block;
      width: 80px;
    }
    input[type="text"] {
      width: calc(100% - 90px);
      padding: 3px;
    }
    /* メディアクエリ */
    @media (max-width: 600px) {
      #header { padding: 8px; font-size: 1.2em; }
      button, select { font-size: 1.2em; padding: 0.1em 0.2em; }
      input[type="text"] { font-size: 1em; }
    }
  </style>
</head>
<body>
  <div id="app">
    <!-- ヘッダー -->
    <div id="header">
      <h1>領収書OCRアプリ</h1>
    </div>
    
    <!-- スクリーン1：画像切り出し＆補正 -->
    <div id="screen1" class="screen active">
      <h2>画像切り出し＆補正</h2>
      <p>画像ファイルを選択し、クロッピング用の編集枠を調整してください。</p>
      <input type="file" id="imageInput" accept="image/*">
      <div id="pcCanvasContainer">
        <canvas id="pcCanvas"></canvas>
      </div>
      <button id="autoCropButton">自動切り出し＆補正を実行</button>
      <button id="confirmPointsButton" style="display:none;">ポイント確定</button>
      <h3>補正結果</h3>
      <img id="correctedImage" alt="Corrected Image">
      <div id="transformControls" style="display:none; margin-top:10px;">
        <button id="rotate90Button">Rotate 90°</button>
        <button id="rotateNeg90Button">Rotate -90°</button>
        <button id="flipButton">Flip Horizontally</button>
      </div>
      <br>
      <button id="nextToScreen2">次へ</button>
    </div>
    
    <!-- スクリーン2：フィールド選択＆OCR -->
    <div id="screen2" class="screen">
      <h2>フィールド選択＆OCR</h2>
      <p>補正済み画像上で、各フィールドの領域を指定してください。</p>
      <label for="fieldSelector">対象項目:</label>
      <select id="fieldSelector">
        <option value="">--フィールドを選択--</option>
        <option value="date">日付</option>
        <option value="amount">金額</option>
        <option value="payee">支払先</option>
        <option value="description">摘要</option>
      </select>
      <div id="fsCanvasContainer">
        <canvas id="fsCanvas"></canvas>
      </div>
      <button id="fsResetButton">フィールドリセット</button>
      <button id="fsOcrButton">選択領域でOCR実行</button>
      <!-- 全体OCR実行ボタン -->
      <button id="ocrWholeButton">全体OCR実行</button>
      <h3>OCR結果</h3>
      <!-- OCR結果表示エリア -->
      <pre id="ocrOutput"></pre>
      <div class="field-group">
        <label for="dateField">日付:</label>
        <input type="text" id="dateField" placeholder="OCR結果">
      </div>
      <div class="field-group">
        <label for="amountField">金額:</label>
        <input type="text" id="amountField" placeholder="OCR結果">
      </div>
      <div class="field-group">
        <label for="payeeField">支払先:</label>
        <input type="text" id="payeeField" placeholder="OCR結果">
      </div>
      <div class="field-group">
        <label for="descriptionField">摘要:</label>
        <input type="text" id="descriptionField" placeholder="OCR結果">
      </div>
      <button id="backToScreen1">戻る</button>
    </div>
  </div>
  
  <!-- ライブラリ読み込み -->
  <!-- Tesseract.js はバージョン 2.1.5 を利用 -->
  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@2.1.5/dist/tesseract.min.js"></script>
  <!-- OpenCV.js（必要に応じて onOpenCvReady() の実装を追加してください） -->
  <script async src="https://docs.opencv.org/3.4.0/opencv.js"></script>
  
  <script>
    /***********************************************************************
     * 以下、画像読み込み、クロッピング、OCR、回転・反転などの実装
     ***********************************************************************/
    
    // 画面遷移用
    function showScreen(screenId) {
      document.querySelectorAll('.screen').forEach(screen => {
        screen.classList.toggle('active', screen.id === screenId);
      });
      if(screenId === 'screen1') drawPcCanvasWithPoints();
      if(screenId === 'screen2') drawFsCanvas();
    }
    
    document.getElementById('nextToScreen2').addEventListener('click', function() {
      if (!correctedImage.src) {
        alert("補正結果画像がありません。");
        return;
      }
      showScreen('screen2');
    });
    
    document.getElementById('backToScreen1').addEventListener('click', function() {
      showScreen('screen1');
    });
    
    // ---------- PCモード（画像切り出し＆補正） ----------
    let pcScale = 1;
    let detectedPoints = [];
    let draggingPointIndex = -1;
    const AREA_THRESHOLD = 10000;
    
    const pcCanvas = document.getElementById('pcCanvas');
    const pcCtx = pcCanvas.getContext('2d');
    let pcImage = new Image();
    
    const imageInput = document.getElementById('imageInput');
    const autoCropButton = document.getElementById('autoCropButton');
    const confirmPointsButton = document.getElementById('confirmPointsButton');
    const correctedImage = document.getElementById('correctedImage');
    const transformControls = document.getElementById('transformControls');
    
    imageInput.addEventListener('change', function(e) {
      if (e.target.files.length > 0) {
        const reader = new FileReader();
        reader.onload = event => { pcImage.src = event.target.result; };
        reader.readAsDataURL(e.target.files[0]);
      }
    });
    
    pcImage.onload = function() {
      const maxDisplayWidth = window.innerWidth - 40;
      pcScale = (pcImage.width > maxDisplayWidth) ? (maxDisplayWidth / pcImage.width) : 1;
      pcCanvas.width = pcImage.width * pcScale;
      pcCanvas.height = pcImage.height * pcScale;
      pcCtx.clearRect(0, 0, pcCanvas.width, pcCanvas.height);
      pcCtx.drawImage(pcImage, 0, 0, pcCanvas.width, pcCanvas.height);
      detectedPoints = [];
      confirmPointsButton.style.display = "none";
      transformControls.style.display = "none";
    };
    
    function autoCrop() {
      if (!pcImage.src) {
        alert("画像が読み込まれていません。");
        return;
      }
      const srcMat = cv.imread(pcCanvas);
      const gray = new cv.Mat();
      cv.cvtColor(srcMat, gray, cv.COLOR_RGBA2GRAY, 0);
      const blurred = new cv.Mat();
      cv.GaussianBlur(gray, blurred, new cv.Size(7, 7), 0);
      const edges = new cv.Mat();
      cv.Canny(blurred, edges, 50, 150);
      const kernel = cv.Mat.ones(3, 3, cv.CV_8U);
      const dilated = new cv.Mat();
      cv.dilate(edges, dilated, kernel);
      
      const contours = new cv.MatVector();
      const hierarchy = new cv.Mat();
      cv.findContours(dilated, contours, hierarchy, cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE);
      
      let maxArea = 0, bestContour = null;
      for (let i = 0; i < contours.size(); i++) {
        const cnt = contours.get(i);
        const peri = cv.arcLength(cnt, true);
        const approx = new cv.Mat();
        cv.approxPolyDP(cnt, approx, 0.02 * peri, true);
        if (approx.rows === 4) {
          const area = cv.contourArea(approx);
          console.log(`Contour ${i} area: ${area}`);
          if (area > AREA_THRESHOLD && area > maxArea) {
            maxArea = area;
            if (bestContour !== null) bestContour.delete();
            bestContour = approx;
          } else {
            approx.delete();
          }
        } else {
          approx.delete();
        }
        cnt.delete();
      }
      hierarchy.delete(); edges.delete(); dilated.delete(); kernel.delete();
      blurred.delete(); gray.delete();
      
      if (bestContour === null) {
        const marginX = pcCanvas.width * 0.1;
        const marginY = pcCanvas.height * 0.1;
        detectedPoints = [
          { x: marginX, y: marginY },
          { x: pcCanvas.width - marginX, y: marginY },
          { x: pcCanvas.width - marginX, y: pcCanvas.height - marginY },
          { x: marginX, y: pcCanvas.height - marginY }
        ];
        console.log("輪郭検出できなかったため、デフォルト枠を設定");
        drawPcCanvasWithPoints();
        confirmPointsButton.style.display = "inline-block";
        srcMat.delete();
        return;
      }
      
      detectedPoints = [];
      for (let i = 0; i < 4; i++) {
        detectedPoints.push({ x: bestContour.intAt(i, 0), y: bestContour.intAt(i, 1) });
      }
      bestContour.delete();
      detectedPoints = orderPoints(detectedPoints);
      console.log("検出された4点（整列後）:", detectedPoints);
      drawPcCanvasWithPoints();
      confirmPointsButton.style.display = "inline-block";
      srcMat.delete();
    }
    
    function orderPoints(pts) {
      const sumArr = pts.map(p => p.x + p.y);
      const diffArr = pts.map(p => p.x - p.y);
      const tl = pts[sumArr.indexOf(Math.min(...sumArr))];
      const br = pts[sumArr.indexOf(Math.max(...sumArr))];
      const tr = pts[diffArr.indexOf(Math.min(...diffArr))];
      const bl = pts[diffArr.indexOf(Math.max(...diffArr))];
      return [tl, tr, br, bl];
    }
    
    function drawPcCanvasWithPoints() {
      pcCtx.clearRect(0, 0, pcCanvas.width, pcCanvas.height);
      pcCtx.drawImage(pcImage, 0, 0, pcCanvas.width, pcCanvas.height);
      detectedPoints.forEach(pt => {
        pcCtx.beginPath();
        pcCtx.arc(pt.x, pt.y, 15, 0, 2 * Math.PI);
        pcCtx.fillStyle = "blue";
        pcCtx.fill();
      });
      if (detectedPoints.length === 4) {
        pcCtx.beginPath();
        pcCtx.moveTo(detectedPoints[0].x, detectedPoints[0].y);
        for (let i = 1; i < 4; i++) {
          pcCtx.lineTo(detectedPoints[i].x, detectedPoints[i].y);
        }
        pcCtx.closePath();
        pcCtx.strokeStyle = "blue";
        pcCtx.lineWidth = 4;
        pcCtx.stroke();
      }
    }
    
    autoCropButton.addEventListener('click', autoCrop);
    
    pcCanvas.addEventListener('pointerdown', function(e) {
      if (detectedPoints.length !== 4) return;
      e.preventDefault();
      const rect = pcCanvas.getBoundingClientRect();
      const scaleX = pcCanvas.width / rect.width;
      const scaleY = pcCanvas.height / rect.height;
      const x = (e.clientX - rect.left) * scaleX;
      const y = (e.clientY - rect.top) * scaleY;
      draggingPointIndex = -1;
      for (let i = 0; i < 4; i++) {
        if (Math.hypot(detectedPoints[i].x - x, detectedPoints[i].y - y) < 15) {
          draggingPointIndex = i;
          break;
        }
      }
    });
    
    pcCanvas.addEventListener('pointermove', function(e) {
      if (draggingPointIndex === -1) return;
      e.preventDefault();
      const rect = pcCanvas.getBoundingClientRect();
      const scaleX = pcCanvas.width / rect.width;
      const scaleY = pcCanvas.height / rect.height;
      const x = (e.clientX - rect.left) * scaleX;
      const y = (e.clientY - rect.top) * scaleY;
      detectedPoints[draggingPointIndex] = { x, y };
      drawPcCanvasWithPoints();
    });
    
    pcCanvas.addEventListener('pointerup', e => { e.preventDefault(); draggingPointIndex = -1; });
    
    confirmPointsButton.addEventListener('click', function() {
      if (detectedPoints.length !== 4) {
        alert("4点が設定されていません。");
        return;
      }
      const ptsOriginal = detectedPoints.map(pt => ({ x: pt.x / pcScale, y: pt.y / pcScale }));
      const [tl, tr, br, bl] = orderPoints(ptsOriginal);
      
      const widthA = Math.hypot(br.x - bl.x, br.y - bl.y);
      const widthB = Math.hypot(tr.x - tl.x, tr.y - tl.y);
      const maxWidth = Math.max(widthA, widthB);
      
      const heightA = Math.hypot(tr.x - br.x, tr.y - br.y);
      const heightB = Math.hypot(tl.x - bl.x, tl.y - bl.y);
      const maxHeight = Math.max(heightA, heightB);
      
      const offCanvas = document.createElement('canvas');
      offCanvas.width = pcImage.width;
      offCanvas.height = pcImage.height;
      const offCtx = offCanvas.getContext('2d');
      offCtx.drawImage(pcImage, 0, 0);
      const srcMat = cv.imread(offCanvas);
      
      const srcPts = cv.matFromArray(4, 1, cv.CV_32FC2, [
        tl.x, tl.y,
        tr.x, tr.y,
        br.x, br.y,
        bl.x, bl.y
      ]);
      const dstPts = cv.matFromArray(4, 1, cv.CV_32FC2, [
        0, 0,
        maxWidth - 1, 0,
        maxWidth - 1, maxHeight - 1,
        0, maxHeight - 1
      ]);
      
      const M = cv.getPerspectiveTransform(srcPts, dstPts);
      const dsize = new cv.Size(maxWidth, maxHeight);
      const dstMat = new cv.Mat();
      cv.warpPerspective(srcMat, dstMat, M, dsize, cv.INTER_LINEAR, cv.BORDER_CONSTANT, new cv.Scalar());
      
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = maxWidth;
      tempCanvas.height = maxHeight;
      cv.imshow(tempCanvas, dstMat);
      const croppedDataURL = tempCanvas.toDataURL();
      
      rotateImage(croppedDataURL, 90)
        .then(rotatedDataURL => flipImage(rotatedDataURL))
        .then(finalDataURL => {
          correctedImage.src = finalDataURL;
          fsImage.src = finalDataURL;
          transformControls.style.display = "block";
        });
      
      srcMat.delete(); dstMat.delete(); srcPts.delete(); dstPts.delete(); M.delete();
      detectedPoints = [];
      confirmPointsButton.style.display = "none";
    });
    
    // ---------- FSモード（フィールド選択＆OCR） ----------
    let fsImage = new Image();
    const fsCanvas = document.getElementById('fsCanvas');
    const fsCtx = fsCanvas.getContext('2d');
    let fsScale = 1;
    let fsFieldRegions = {};
    
    const fieldSelector = document.getElementById('fieldSelector');
    const fsResetButton = document.getElementById('fsResetButton');
    const fsOcrButton = document.getElementById('fsOcrButton');
    const ocrWholeButton = document.getElementById('ocrWholeButton');
    const ocrOutput = document.getElementById('ocrOutput');
    const dateField = document.getElementById('dateField');
    const amountField = document.getElementById('amountField');
    const payeeField = document.getElementById('payeeField');
    const descriptionField = document.getElementById('descriptionField');
    
    fsImage.onload = function() {
      const maxDisplayWidth = window.innerWidth - 40;
      fsScale = (fsImage.width > maxDisplayWidth) ? (maxDisplayWidth / fsImage.width) : 1;
      fsCanvas.width = fsImage.width * fsScale;
      fsCanvas.height = fsImage.height * fsScale;
      fsFieldRegions = {};
      drawFsCanvas();
    };
    
    function drawFsCanvas() {
      fsCtx.clearRect(0, 0, fsCanvas.width, fsCanvas.height);
      fsCtx.drawImage(fsImage, 0, 0, fsCanvas.width, fsCanvas.height);
      // ユーザー指定の領域枠（赤）はそのまま描画
      for (const field in fsFieldRegions) {
        if (field === "amount" && Array.isArray(fsFieldRegions[field])) {
          fsFieldRegions[field].forEach(region => {
            fsCtx.strokeStyle = "red";
            fsCtx.lineWidth = 4;
            fsCtx.strokeRect(region.x, region.y, region.width, region.height);
            fsCtx.fillStyle = "rgba(255,255,255,0.7)";
            fsCtx.fillRect(region.x, region.y - 20, 60, 20);
            fsCtx.fillStyle = "red";
            fsCtx.font = "14px Arial";
            fsCtx.fillText(field, region.x + 2, region.y - 5);
          });
        } else {
          const r = fsFieldRegions[field];
          fsCtx.strokeStyle = "red";
          fsCtx.lineWidth = 4;
          fsCtx.strokeRect(r.x, r.y, r.width, r.height);
          fsCtx.fillStyle = "rgba(255,255,255,0.7)";
          fsCtx.fillRect(r.x, r.y - 20, 50, 20);
          fsCtx.fillStyle = "red";
          fsCtx.font = "14px Arial";
          fsCtx.fillText(field, r.x + 2, r.y - 5);
        }
      }
    }
    
    let fsIsDrawing = false, fsStartX, fsStartY, fsCurrentX, fsCurrentY;
    
    fsCanvas.addEventListener('pointerdown', function(e) {
      if (!fieldSelector.value) {
        alert("まずは対象項目を選択してください。");
        return;
      }
      e.preventDefault();
      const rect = fsCanvas.getBoundingClientRect();
      const scaleX = fsCanvas.width / rect.width;
      const scaleY = fsCanvas.height / rect.height;
      fsStartX = (e.clientX - rect.left) * scaleX;
      fsStartY = (e.clientY - rect.top) * scaleY;
      fsIsDrawing = true;
    });
    
    fsCanvas.addEventListener('pointermove', function(e) {
      if (!fsIsDrawing) return;
      e.preventDefault();
      const rect = fsCanvas.getBoundingClientRect();
      const scaleX = fsCanvas.width / rect.width;
      const scaleY = fsCanvas.height / rect.height;
      fsCurrentX = (e.clientX - rect.left) * scaleX;
      fsCurrentY = (e.clientY - rect.top) * scaleY;
      drawFsCanvas();
      fsCtx.strokeStyle = "blue";
      fsCtx.lineWidth = 4;
      fsCtx.strokeRect(fsStartX, fsStartY, fsCurrentX - fsStartX, fsCurrentY - fsStartY);
    });
    
    fsCanvas.addEventListener('pointerup', function(e) {
      if (!fsIsDrawing) return;
      e.preventDefault();
      fsIsDrawing = false;
      const rect = fsCanvas.getBoundingClientRect();
      const scaleX = fsCanvas.width / rect.width;
      const scaleY = fsCanvas.height / rect.height;
      fsCurrentX = (e.clientX - rect.left) * scaleX;
      fsCurrentY = (e.clientY - rect.top) * scaleY;
      const x = Math.min(fsStartX, fsCurrentX);
      const y = Math.min(fsStartY, fsCurrentY);
      const width = Math.abs(fsCurrentX - fsStartX);
      const height = Math.abs(fsCurrentY - fsStartY);
      if (width === 0 || height === 0) return;
      const field = fieldSelector.value;
      if (field === "amount") {
        if (!fsFieldRegions[field]) fsFieldRegions[field] = [];
        fsFieldRegions[field].push({ x, y, width, height });
      } else {
        fsFieldRegions[field] = { x, y, width, height };
      }
      drawFsCanvas();
    });
    
    fsResetButton.addEventListener('click', function() {
      fsFieldRegions = {};
      drawFsCanvas();
    });
    
    fsOcrButton.addEventListener('click', function() {
      ocrOutput.textContent = "各領域のOCR処理中…\n";
      const tasks = [];
      for (const field in fsFieldRegions) {
        if (field === "amount" && Array.isArray(fsFieldRegions[field])) {
          let amountPromises = fsFieldRegions[field].map(region => performOCROnField("amount", region));
          tasks.push(
            Promise.all(amountPromises).then(results => {
              let total = results.reduce((sum, text) => {
                let num = parseInt(processAmountField(text), 10);
                return sum + (isNaN(num) ? 0 : num);
              }, 0);
              amountField.value = total;
              ocrOutput.textContent += `amount: ${total}\n`;
            })
          );
        } else {
          tasks.push(
            performOCROnField(field, fsFieldRegions[field]).then(resultText => {
              if (field === "date") {
                resultText = processDateField(resultText);
                dateField.value = resultText;
              } else if (field === "payee") {
                payeeField.value = resultText;
              } else if (field === "description") {
                descriptionField.value = resultText;
              }
              ocrOutput.textContent += `${field}: ${resultText}\n`;
            })
          );
        }
      }
      Promise.all(tasks).then(() => {
        ocrOutput.textContent += "全領域のOCR処理完了。";
      });
    });
    
    // ---------- 全体OCR実行（ワーカーAPI版） ----------
    ocrWholeButton.addEventListener('click', async function() {
      ocrOutput.textContent = "全体OCR実行中...\n";
      if (!fsImage.src) {
        console.error("fsImage.src が設定されていません。");
        ocrOutput.textContent += "エラー: 画像が読み込まれていません。\n";
        return;
      }
      const worker = Tesseract.createWorker({
        logger: m => console.log("全体OCR:", m)
      });
      try {
        await worker.load();
        await worker.loadLanguage('jpn');
        await worker.initialize('jpn');
        const { data } = await worker.recognize(fsImage.src);
        ocrOutput.textContent += "全体OCR完了。\n";
        // 個々の単語枠は描画せず、グループ化して枠を表示
        displayGroupedText(data);
      } catch (err) {
        console.error("全体OCRエラー:", err);
        ocrOutput.textContent += "エラーが発生しました。\n" + err;
      } finally {
        await worker.terminate();
      }
    });
    
    /**
     * グループ化されたOCR結果を表示するとともに、各グループの領域を計算して横方向の重なりがあるもののみをマージし、
     * マージされた領域に対して再OCRを実施する
     * @param {Object} data - Tesseract OCR の結果オブジェクト
     */
    function displayGroupedText(data) {
      const groups = groupWordsByLine(data.words, 10);
      let groupedText = "\n【グループ化されたOCR結果】\n";
      let boxes = [];
      groups.forEach((group, index) => {
        const lineText = group.map(word => word.text).join(" ").trim();
        groupedText += `Line ${index + 1}: ${lineText ? lineText : "認識なし"}\n`;
        // 各グループの領域を計算（元画像座標）
        const box = computeGroupBoundingBox(group);
        // fsCanvas上の座標に変換（fsScaleを掛ける）
        boxes.push({ 
          x: box.minX * fsScale, 
          y: box.minY * fsScale, 
          width: (box.maxX - box.minX) * fsScale, 
          height: (box.maxY - box.minY) * fsScale 
        });
      });
      ocrOutput.textContent += groupedText;
      console.log(groupedText);
      // マージ処理：ここでは横方向の重なりがある場合のみマージする（横方向オーバーラップの割合が50%以上の場合）
      const mergedBoxes = mergeOverlappingBoxes(boxes);
      // マージ後の枠を描画
      drawGroupedBoxes(mergedBoxes);
      // マージされた各領域内で再OCR実施
      reOcrMergedBoxes(mergedBoxes);
    }
    
    /**
     * グループ内の単語から領域（バウンディングボックス）を計算する
     * @param {Array} group - 単語オブジェクトの配列
     * @returns {Object} - { minX, minY, maxX, maxY } の領域情報
     */
    function computeGroupBoundingBox(group) {
      let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;
      group.forEach(word => {
        const { x0, y0, x1, y1 } = word.bbox;
        minX = Math.min(minX, x0);
        minY = Math.min(minY, y0);
        maxX = Math.max(maxX, x1);
        maxY = Math.max(maxY, y1);
      });
      return { minX, minY, maxX, maxY };
    }
    
    /**
     * OCR結果の単語配列を、bbox の y 座標でグループ化して行ごとにまとめる
     * @param {Array} words - Tesseract OCR の data.words 配列
     * @param {number} threshold - y 座標の差分の閾値（ピクセル単位）
     * @returns {Array} - 行ごとの単語の2次元配列
     */
    function groupWordsByLine(words, threshold = 10) {
      words.sort((a, b) => a.bbox.y0 - b.bbox.y0);
      const groups = [];
      let currentGroup = [];
      let currentY = null;
      words.forEach(word => {
        if (currentY === null) {
          currentY = word.bbox.y0;
          currentGroup.push(word);
        } else {
          if (Math.abs(word.bbox.y0 - currentY) < threshold) {
            currentGroup.push(word);
          } else {
            groups.push(currentGroup);
            currentGroup = [word];
            currentY = word.bbox.y0;
          }
        }
      });
      if (currentGroup.length > 0) groups.push(currentGroup);
      return groups;
    }
    
    /**
     * 2つの矩形が横方向に十分な重なりがあるかどうか判定する
     * ※ここでは、2つの矩形の横方向の重なり幅が、小さい方の幅の50%以上の場合のみ重なっていると判断する
     * @param {Object} box1 - {x, y, width, height}
     * @param {Object} box2 - {x, y, width, height}
     * @returns {boolean} - 十分な横方向の重なりがあれば true
     */
    function isOverlap(box1, box2) {
      const left = Math.max(box1.x, box2.x);
      const right = Math.min(box1.x + box1.width, box2.x + box2.width);
      const overlapWidth = right - left;
      if (overlapWidth <= 0) return false;
      const minWidth = Math.min(box1.width, box2.width);
      return (overlapWidth >= 1.4 * minWidth);　// 140%以上の重なりがあるかどうか
    }
    
    /**
     * 2つの矩形のユニオン（合体）を返す
     * @param {Object} box1
     * @param {Object} box2
     * @returns {Object} - マージされた矩形
     */
    function unionBox(box1, box2) {
      const x = Math.min(box1.x, box2.x);
      const y = Math.min(box1.y, box2.y);
      const right = Math.max(box1.x + box1.width, box2.x + box2.width);
      const bottom = Math.max(box1.y + box1.height, box2.y + box2.height);
      return { x, y, width: right - x, height: bottom - y };
    }
    
    /**
     * 複数の矩形のうち、横方向に十分な重なりがあるものをマージする
     * @param {Array} boxes - 各矩形は {x, y, width, height}
     * @returns {Array} - マージ後の矩形配列
     */
    function mergeOverlappingBoxes(boxes) {
      let merged = boxes.slice();
      let didMerge = true;
      while(didMerge) {
        didMerge = false;
        let newMerged = [];
        let used = new Array(merged.length).fill(false);
        for (let i = 0; i < merged.length; i++) {
          if (used[i]) continue;
          let current = merged[i];
          for (let j = i + 1; j < merged.length; j++) {
            if (used[j]) continue;
            if (isOverlap(current, merged[j])) {
              current = unionBox(current, merged[j]);
              used[j] = true;
              didMerge = true;
            }
          }
          newMerged.push(current);
        }
        merged = newMerged;
      }
      return merged;
    }
    
    /**
     * マージされた各グループ領域を fsCanvas 上に描画する
     * @param {Array} boxes - マージ後の矩形配列（各矩形は {x, y, width, height}）
     */
    function drawGroupedBoxes(boxes) {
      boxes.forEach((box, index) => {
        fsCtx.strokeStyle = "magenta";
        fsCtx.lineWidth = 3;
        fsCtx.strokeRect(box.x, box.y, box.width, box.height);
        fsCtx.fillStyle = "magenta";
        fsCtx.font = "16px Arial";
        fsCtx.fillText("Group " + (index + 1), box.x, box.y - 5);
      });
    }
    
    /**
     * マージされた各領域内で再OCRを実施し、その結果を枠ラベルとして描画する
     * @param {Array} mergedBoxes - マージされた矩形配列
     */
    async function reOcrMergedBoxes(mergedBoxes) {
      for (let i = 0; i < mergedBoxes.length; i++) {
        let box = mergedBoxes[i];
        // 元画像上の座標に変換
        let originalX = box.x / fsScale;
        let originalY = box.y / fsScale;
        let originalWidth = box.width / fsScale;
        let originalHeight = box.height / fsScale;
        let tempCanvas = document.createElement('canvas');
        tempCanvas.width = originalWidth;
        tempCanvas.height = originalHeight;
        let tempCtx = tempCanvas.getContext('2d');
        // fsImage（補正済み画像）から切り出し
        tempCtx.drawImage(fsImage, originalX, originalY, originalWidth, originalHeight, 0, 0, originalWidth, originalHeight);
        let croppedDataURL = tempCanvas.toDataURL();
        const worker = Tesseract.createWorker({ logger: m => console.log("Merged OCR:", m) });
        await worker.load();
        await worker.loadLanguage('jpn');
        await worker.initialize('jpn');
        const { data } = await worker.recognize(croppedDataURL);
        await worker.terminate();
        let text = data.text.trim();
        if (!text) text = "認識なし";
        // マージ枠を青色で再描画し、ラベルにOCR結果を表示
        fsCtx.strokeStyle = "blue";
        fsCtx.lineWidth = 3;
        fsCtx.strokeRect(box.x, box.y, box.width, box.height);
        fsCtx.fillStyle = "blue";
        fsCtx.font = "16px Arial";
        fsCtx.fillText("Merged: " + text, box.x, box.y - 5);
      }
    }
    
    /**
     * グループ化されたOCR結果を表示し、各グループの領域を計算して横方向の重なりがあるもののみをマージし、
     * マージされた領域に対して再OCRを実施する
     * @param {Object} data - Tesseract OCR の結果オブジェクト
     */
    function displayGroupedText(data) {
      const groups = groupWordsByLine(data.words, 10);
      let groupedText = "\n【グループ化されたOCR結果】\n";
      let boxes = [];
      groups.forEach((group, index) => {
        const lineText = group.map(word => word.text).join(" ").trim();
        groupedText += `Line ${index + 1}: ${lineText ? lineText : "認識なし"}\n`;
        // 各グループの領域を計算（元画像座標）
        const box = computeGroupBoundingBox(group);
        // fsCanvas上の座標に変換（fsScaleを掛ける）
        boxes.push({ 
          x: box.minX * fsScale, 
          y: box.minY * fsScale, 
          width: (box.maxX - box.minX) * fsScale, 
          height: (box.maxY - box.minY) * fsScale 
        });
      });
      ocrOutput.textContent += groupedText;
      console.log(groupedText);
      // マージ処理：横方向の重なりがある場合のみマージする（横方向オーバーラップの割合が50%以上の場合）
      const mergedBoxes = mergeOverlappingBoxes(boxes);
      // マージ後の枠を描画
      drawGroupedBoxes(mergedBoxes);
      // マージされた各領域内で再OCR実施
      reOcrMergedBoxes(mergedBoxes);
    }
    
    function performOCROnField(field, region) {
      return new Promise((resolve, reject) => {
        const originalX = region.x / fsScale;
        const originalY = region.y / fsScale;
        const originalWidth = region.width / fsScale;
        const originalHeight = region.height / fsScale;
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = originalWidth;
        tempCanvas.height = originalHeight;
        const tempCtx = tempCanvas.getContext('2d');
        tempCtx.drawImage(fsImage, originalX, originalY, originalWidth, originalHeight, 0, 0, originalWidth, originalHeight);
        const croppedDataURL = tempCanvas.toDataURL();
        binarizeImage(croppedDataURL).then(binarizedDataURL => {
          Tesseract.recognize(
            binarizedDataURL,
            'jpn',
            {
              langPath: 'https://tessdata.projectnaptha.com/4.0.0_best/',
              logger: m => console.log(field, m),
              tessedit_char_whitelist: '0123456789年月日-/： ',
              tessedit_pageseg_mode: 6
            }
          ).then(({ data: { text } }) => {
            resolve(replaceCircledNumbers(text).trim());
          }).catch(err => {
            console.error(field, err);
            resolve("エラー");
          });
        }).catch(err => {
          console.error("Binarization error", err);
          resolve("エラー");
        });
      });
    }
    
    function binarizeImage(dataURL) {
      return new Promise((resolve, reject) => {
        const img = new Image();
        img.onload = function() {
          const canvas = document.createElement('canvas');
          canvas.width = img.width;
          canvas.height = img.height;
          const ctx = canvas.getContext('2d');
          ctx.drawImage(img, 0, 0);
          const src = cv.imread(canvas);
          const gray = new cv.Mat();
          cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
          const binary = new cv.Mat();
          cv.threshold(gray, binary, 128, 255, cv.THRESH_BINARY);
          cv.imshow(canvas, binary);
          const resultDataURL = canvas.toDataURL();
          src.delete(); gray.delete(); binary.delete();
          resolve(resultDataURL);
        };
        img.onerror = function(err) { reject(err); };
        img.src = dataURL;
      });
    }
    
    function replaceCircledNumbers(text) {
      const mapping = {
        '⓪': '0', '①': '1', '②': '2', '③': '3', '④': '4',
        '⑤': '5', '⑥': '6', '⑦': '7', '⑧': '8', '⑨': '9',
        '⑩': '10', '⑪': '11', '⑫': '12'
      };
      return text.replace(/[⓪①②③④⑤⑥⑦⑧⑨⑩⑪⑫]/g, match => mapping[match] || match);
    }
    
    function processDateField(text) {
      if (text.includes("令和") || text.includes("平成") || text.includes("昭和")) {
        return convertJapaneseEra(text);
      }
      return text;
    }
    
    function processAmountField(text) {
      return text.replace(/\D/g, "");
    }
    
    function convertJapaneseEra(dateStr) {
      const match = dateStr.match(/(令和|平成|昭和)(元|\d+)[年](\d{1,2})[月](\d{1,2})[日]/);
      if (match) {
        const era = match[1];
        const yearPart = match[2];
        const month = match[3];
        const day = match[4];
        let offset = 0;
        if (era === "令和") offset = 2018;
        else if (era === "平成") offset = 1988;
        else if (era === "昭和") offset = 1925;
        const year = (yearPart === "元") ? offset + 1 : parseInt(yearPart, 10) + offset;
        return year + "年" + month + "月" + day + "日";
      }
      return dateStr;
    }
    
    // ---------- 回転・反転処理 ----------
    const rotate90Button = document.getElementById('rotate90Button');
    const rotateNeg90Button = document.getElementById('rotateNeg90Button');
    const flipButton = document.getElementById('flipButton');
    
    rotate90Button.addEventListener('click', function() {
      rotateImage(correctedImage.src, 90).then(newDataURL => {
        correctedImage.src = newDataURL;
        fsImage.src = newDataURL;
      });
    });
    
    rotateNeg90Button.addEventListener('click', function() {
      rotateImage(correctedImage.src, -90).then(newDataURL => {
        correctedImage.src = newDataURL;
        fsImage.src = newDataURL;
      });
    });
    
    flipButton.addEventListener('click', function() {
      flipImage(correctedImage.src).then(newDataURL => {
        correctedImage.src = newDataURL;
        fsImage.src = newDataURL;
      });
    });
    
    function rotateImage(dataURL, angle) {
      return new Promise((resolve, reject) => {
        const img = new Image();
        img.onload = function() {
          const canvas = document.createElement('canvas');
          const ctx = canvas.getContext('2d');
          if (angle % 180 !== 0) {
            canvas.width = img.height;
            canvas.height = img.width;
          } else {
            canvas.width = img.width;
            canvas.height = img.height;
          }
          ctx.save();
          ctx.translate(canvas.width / 2, canvas.height / 2);
          ctx.rotate(angle * Math.PI / 180);
          ctx.drawImage(img, -img.width / 2, -img.height / 2);
          ctx.restore();
          resolve(canvas.toDataURL());
        };
        img.onerror = reject;
        img.src = dataURL;
      });
    }
    
    function flipImage(dataURL) {
      return new Promise((resolve, reject) => {
        const img = new Image();
        img.onload = function() {
          const canvas = document.createElement('canvas');
          canvas.width = img.width;
          canvas.height = img.height;
          const ctx = canvas.getContext('2d');
          ctx.save();
          ctx.translate(img.width, 0);
          ctx.scale(-1, 1);
          ctx.drawImage(img, 0, 0);
          ctx.restore();
          resolve(canvas.toDataURL());
        };
        img.onerror = reject;
        img.src = dataURL;
      });
    }
    
    // ※ OpenCV.js の onOpenCvReady() の実装は各環境に合わせてご用意ください。
  </script>
</body>
</html>
